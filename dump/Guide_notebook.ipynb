{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:30:52.777960Z",
     "iopub.status.busy": "2023-02-17T08:30:52.776930Z",
     "iopub.status.idle": "2023-02-17T08:30:59.251225Z",
     "shell.execute_reply": "2023-02-17T08:30:59.250066Z",
     "shell.execute_reply.started": "2023-02-17T08:30:52.777838Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from albumentations import Compose, Normalize, RandomCrop, HorizontalFlip, ShiftScaleRotate, HueSaturationValue\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchmetrics import AUROC\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:30:59.253824Z",
     "iopub.status.busy": "2023-02-17T08:30:59.253453Z",
     "iopub.status.idle": "2023-02-17T08:31:11.444048Z",
     "shell.execute_reply": "2023-02-17T08:31:11.442761Z",
     "shell.execute_reply.started": "2023-02-17T08:30:59.253788Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding RLEs into masks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:31:11.447064Z",
     "iopub.status.busy": "2023-02-17T08:31:11.446639Z",
     "iopub.status.idle": "2023-02-17T08:31:11.456671Z",
     "shell.execute_reply": "2023-02-17T08:31:11.455065Z",
     "shell.execute_reply.started": "2023-02-17T08:31:11.447025Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_rle_to_mask(rle, height, width, viz=False):\n",
    "    '''\n",
    "    rle : run-length as string formated (start value, count)\n",
    "    height : height of the mask \n",
    "    width : width of the mask\n",
    "    returns binary mask\n",
    "    '''\n",
    "    rle = np.array(rle.split(' ')).reshape(-1, 2)\n",
    "    mask = np.zeros((height*width, 1, 3))\n",
    "    if viz:\n",
    "        color = np.random.rand(3)\n",
    "    else:\n",
    "        color = [1,1,1]\n",
    "    for i in rle:\n",
    "        mask[int(i[0]):int(i[0])+int(i[1]), :, :] = color\n",
    "\n",
    "    return mask.reshape(height, width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:31:15.635148Z",
     "iopub.status.busy": "2023-02-17T08:31:15.634433Z",
     "iopub.status.idle": "2023-02-17T08:31:15.972629Z",
     "shell.execute_reply": "2023-02-17T08:31:15.971598Z",
     "shell.execute_reply.started": "2023-02-17T08:31:15.635112Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/Multiclass-segmentation/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:31:16.105585Z",
     "iopub.status.busy": "2023-02-17T08:31:16.105039Z",
     "iopub.status.idle": "2023-02-17T08:31:16.132404Z",
     "shell.execute_reply": "2023-02-17T08:31:16.131511Z",
     "shell.execute_reply.started": "2023-02-17T08:31:16.105549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ClassNumber</th>\n",
       "      <th>Encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_006280</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>60301 3 60798 7 61296 9 61795 10 62293 12 6279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_006280</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>94789 3 95289 6 95789 8 96288 11 96788 13 9728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008_006280</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>125167 1 125666 5 126166 6 126665 8 127165 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008_006285</td>\n",
       "      <td>334</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>5323 4 5821 7 6319 9 6818 10 7218 5 7316 11 77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008_006285</td>\n",
       "      <td>334</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>51316 2 51320 1 51814 8 52313 9 52387 2 52812 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>2010_006079</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>87214 4 87711 9 88209 12 88708 14 89207 16 897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>2010_006086</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>45665 5 46162 9 46603 5 46639 7 46656 16 47099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>2010_006086</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>56191 3 56691 6 56718 6 57191 9 57211 28 57675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>2010_006086</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>81612 2 82102 13 82589 27 83087 30 83531 22 83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>2010_006086</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>94897 3 95392 8 95891 9 96389 10 96887 12 9738...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6784 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageName  ImageWidth  ImageHeight  ClassNumber  \\\n",
       "0     2008_006280         375          500            1   \n",
       "1     2008_006280         375          500            2   \n",
       "2     2008_006280         375          500            3   \n",
       "3     2008_006285         334          500            1   \n",
       "4     2008_006285         334          500            2   \n",
       "...           ...         ...          ...          ...   \n",
       "6779  2010_006079         375          500            3   \n",
       "6780  2010_006086         375          500            1   \n",
       "6781  2010_006086         375          500            2   \n",
       "6782  2010_006086         375          500            3   \n",
       "6783  2010_006086         375          500            4   \n",
       "\n",
       "                                               Encoding  \n",
       "0     60301 3 60798 7 61296 9 61795 10 62293 12 6279...  \n",
       "1     94789 3 95289 6 95789 8 96288 11 96788 13 9728...  \n",
       "2     125167 1 125666 5 126166 6 126665 8 127165 9 1...  \n",
       "3     5323 4 5821 7 6319 9 6818 10 7218 5 7316 11 77...  \n",
       "4     51316 2 51320 1 51814 8 52313 9 52387 2 52812 ...  \n",
       "...                                                 ...  \n",
       "6779  87214 4 87711 9 88209 12 88708 14 89207 16 897...  \n",
       "6780  45665 5 46162 9 46603 5 46639 7 46656 16 47099...  \n",
       "6781  56191 3 56691 6 56718 6 57191 9 57211 28 57675...  \n",
       "6782  81612 2 82102 13 82589 27 83087 30 83531 22 83...  \n",
       "6783  94897 3 95392 8 95891 9 96389 10 96887 12 9738...  \n",
       "\n",
       "[6784 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:45:26.076648Z",
     "iopub.status.busy": "2023-02-17T08:45:26.076287Z",
     "iopub.status.idle": "2023-02-17T08:46:11.484999Z",
     "shell.execute_reply": "2023-02-17T08:46:11.483967Z",
     "shell.execute_reply.started": "2023-02-17T08:45:26.076617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dfcp:  2172\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/Multiclass-segmentation/train.csv')\n",
    "dfcp=df.copy()\n",
    "dfcp = dfcp.drop_duplicates(subset=['ImageName'], keep='first')\n",
    "print('length of dfcp: ', len(dfcp))\n",
    "traindata={\"imgs\":[],\"masks\":[]}\n",
    "path='/kaggle/input/Multiclass-segmentation/TrainImages'\n",
    "ext='.jpg'\n",
    "\n",
    "for i in dfcp['ImageName']:\n",
    "    imgpath=os.path.join(path,i+ext)\n",
    "    masks=[]\n",
    "    num=0\n",
    "    for j in df[df['ImageName'] == i]['Encoding']:\n",
    "        hi = df[df['ImageName'] == i]['ImageWidth'].values[0]\n",
    "        wi = df[df['ImageName'] == i]['ImageHeight'].values[0]\n",
    "        classes = int(df[df['ImageName'] == i]['ClassNumber'].values[num])\n",
    "        masks.append(decode_rle_to_mask(j, int(hi), int(wi))*classes)\n",
    "        num+=1\n",
    "    img = cv2.imread(imgpath)  \n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    traindata['imgs'].append(np.array(img_resized, dtype=np.float16))\n",
    "    mask = np.sum(masks, axis=0)[:,:,0]\n",
    "    mask_resized = cv2.resize(mask, (224, 224), interpolation = cv2.INTER_NEAREST)\n",
    "    traindata['masks'].append(np.array(mask_resized, dtype=np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:17.042695Z",
     "iopub.status.busy": "2023-02-17T08:46:17.042295Z",
     "iopub.status.idle": "2023-02-17T08:46:17.053502Z",
     "shell.execute_reply": "2023-02-17T08:46:17.052493Z",
     "shell.execute_reply.started": "2023-02-17T08:46:17.042663Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/Multiclass-segmentation/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:17.767257Z",
     "iopub.status.busy": "2023-02-17T08:46:17.766879Z",
     "iopub.status.idle": "2023-02-17T08:46:17.776561Z",
     "shell.execute_reply": "2023-02-17T08:46:17.775143Z",
     "shell.execute_reply.started": "2023-02-17T08:46:17.767223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.], dtype=float16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(traindata['masks'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:18.622835Z",
     "iopub.status.busy": "2023-02-17T08:46:18.622107Z",
     "iopub.status.idle": "2023-02-17T08:46:18.641612Z",
     "shell.execute_reply": "2023-02-17T08:46:18.640583Z",
     "shell.execute_reply.started": "2023-02-17T08:46:18.622788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>Encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_000008</td>\n",
       "      <td>442</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_000009</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008_000019</td>\n",
       "      <td>272</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008_000026</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008_000053</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>46</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>47</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>48</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>49</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageName  ImageHeight  ImageWidth  Encoding\n",
       "0    2008_000008          442         500       NaN\n",
       "1    2008_000009          375         500       NaN\n",
       "2    2008_000019          272         480       NaN\n",
       "3    2008_000026          375         500       NaN\n",
       "4    2008_000053          375         500       NaN\n",
       "..           ...          ...         ...       ...\n",
       "977           46         1024         768       NaN\n",
       "978           47         1024         768       NaN\n",
       "979           48         1024         768       NaN\n",
       "980           49         1024         768       NaN\n",
       "981           50         1024         768       NaN\n",
       "\n",
       "[982 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:21.380154Z",
     "iopub.status.busy": "2023-02-17T08:46:21.379782Z",
     "iopub.status.idle": "2023-02-17T08:46:21.386762Z",
     "shell.execute_reply": "2023-02-17T08:46:21.385380Z",
     "shell.execute_reply.started": "2023-02-17T08:46:21.380122Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/kaggle/input/Multiclass-segmentation/TestImages/1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:23.019235Z",
     "iopub.status.busy": "2023-02-17T08:46:23.018853Z",
     "iopub.status.idle": "2023-02-17T08:46:23.024871Z",
     "shell.execute_reply": "2023-02-17T08:46:23.023496Z",
     "shell.execute_reply.started": "2023-02-17T08:46:23.019206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:24.326991Z",
     "iopub.status.busy": "2023-02-17T08:46:24.326297Z",
     "iopub.status.idle": "2023-02-17T08:46:40.504940Z",
     "shell.execute_reply": "2023-02-17T08:46:40.503794Z",
     "shell.execute_reply.started": "2023-02-17T08:46:24.326954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dfcp:  982\n"
     ]
    }
   ],
   "source": [
    "df_testcp=df_test.copy()\n",
    "df_testcp = df_testcp.drop_duplicates(subset=['ImageName'], keep='first')\n",
    "print('length of dfcp: ', len(df_testcp))\n",
    "testdata={\"imgs\":[]}\n",
    "path='/kaggle/input/Multiclass-segmentation/TestImages'\n",
    "ext='.jpg'\n",
    "\n",
    "value = \"\"\n",
    "for i in df_testcp['ImageName']:\n",
    "    if(len(i)) == 1:\n",
    "        value = \"0\"\n",
    "    else:\n",
    "        value = \"\"\n",
    "    imgpath=os.path.join(path,value+i+ext)\n",
    "    img = cv2.imread(imgpath)\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    testdata['imgs'].append(np.array(img_resized, dtype=np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:40.509783Z",
     "iopub.status.busy": "2023-02-17T08:46:40.508830Z",
     "iopub.status.idle": "2023-02-17T08:46:40.516816Z",
     "shell.execute_reply": "2023-02-17T08:46:40.515808Z",
     "shell.execute_reply.started": "2023-02-17T08:46:40.509742Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_test(img, mask):\n",
    "    data_transforms = Compose([\n",
    "                        HorizontalFlip(),\n",
    "                       # add more\n",
    "                        \n",
    "                        Normalize(),\n",
    "                        ToTensorV2()\n",
    "                    ])\n",
    "    img= img.astype(\"float32\")\n",
    "    mask = mask.astype(\"float32\")\n",
    "    sample = {\n",
    "              \"image\":img,\n",
    "              \"mask\": mask,\n",
    "              \n",
    "          }\n",
    "    sample = data_transforms(**sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:40.520967Z",
     "iopub.status.busy": "2023-02-17T08:46:40.520218Z",
     "iopub.status.idle": "2023-02-17T08:46:40.528030Z",
     "shell.execute_reply": "2023-02-17T08:46:40.526909Z",
     "shell.execute_reply.started": "2023-02-17T08:46:40.520924Z"
    }
   },
   "outputs": [],
   "source": [
    "# imgs_test = []\n",
    "# for i in range(len(testdata['imgs'])):\n",
    "#     imgs_train.append(transform(testdata['imgs'][i],testdata['masks'][i] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:40.530892Z",
     "iopub.status.busy": "2023-02-17T08:46:40.530377Z",
     "iopub.status.idle": "2023-02-17T08:46:40.539769Z",
     "shell.execute_reply": "2023-02-17T08:46:40.538710Z",
     "shell.execute_reply.started": "2023-02-17T08:46:40.530853Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(img, mask):\n",
    "    data_transforms = Compose([\n",
    "                        HorizontalFlip(),\n",
    "                        # add more\n",
    "\n",
    "\n",
    "                        Normalize(),\n",
    "                        ToTensorV2()\n",
    "                    ])\n",
    "    img= img.astype(\"float32\")\n",
    "    mask = mask.astype(\"int64\")\n",
    "    sample = {\n",
    "              \"image\":img,\n",
    "              \"mask\": mask,\n",
    "              \n",
    "          }\n",
    "    sample = data_transforms(**sample)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: add more functions inside Compose for increase the segmentation. Read the documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:40.541734Z",
     "iopub.status.busy": "2023-02-17T08:46:40.541343Z",
     "iopub.status.idle": "2023-02-17T08:46:48.038640Z",
     "shell.execute_reply": "2023-02-17T08:46:48.037515Z",
     "shell.execute_reply.started": "2023-02-17T08:46:40.541700Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs_train = []\n",
    "for i in range(len(traindata['imgs'])):\n",
    "    imgs_train.append(transform(traindata['imgs'][i],traindata['masks'][i] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:46:48.041242Z",
     "iopub.status.busy": "2023-02-17T08:46:48.040738Z",
     "iopub.status.idle": "2023-02-17T08:46:48.051846Z",
     "shell.execute_reply": "2023-02-17T08:46:48.050629Z",
     "shell.execute_reply.started": "2023-02-17T08:46:48.041200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:47:03.913947Z",
     "iopub.status.busy": "2023-02-17T08:47:03.913588Z",
     "iopub.status.idle": "2023-02-17T08:47:03.921937Z",
     "shell.execute_reply": "2023-02-17T08:47:03.920698Z",
     "shell.execute_reply.started": "2023-02-17T08:47:03.913915Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a9a4af2334f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m dataloaders = {\n\u001b[0;32m----> 4\u001b[0;31m     'train': torch.utils.data.DataLoader(imgs_train[:1520], batch_size=8,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                             shuffle=True, num_workers=2),\n\u001b[1;32m      6\u001b[0m     'test': torch.utils.data.DataLoader(imgs_train[1520:], batch_size=8, #sampler = sampler3,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_train' is not defined"
     ]
    }
   ],
   "source": [
    "Test_split = 100\n",
    "\n",
    "\n",
    "\n",
    "#change the number make it 80% of data\n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(imgs_train[:Test_split], batch_size=8,\n",
    "                                            shuffle=True, num_workers=2),\n",
    "    'test': torch.utils.data.DataLoader(imgs_train[Test_split:], batch_size=8, #sampler = sampler3,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "                                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_image_train = next(iter(dataloaders['train']['image']))# should be 8 * 224 * 224 * 3 because number of batches = 8\n",
    "ex_mask_train = next(iter(dataloaders['train']['mask']))# should be 8 * 224 * 224 * 1 because number of batches = 8\n",
    "print(ex_image_train.shape)\n",
    "#Next iter just gives Example of 8 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_image_test = next(iter(dataloaders['test']['image']))# should be 8 * 224 * 224 * 3 because number of batches = 8\n",
    "ex_mask_test = next(iter(dataloaders['test']['mask']))# should be 8 * 224 * 224 * 1 because number of batches = 8\n",
    "\n",
    "print(ex_image_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next(iter()) gives you one example from itererable object it is equals = i when you loop like ig you looped on \n",
    "dataloaders: \n",
    "\n",
    "    For i in dataloaders:\n",
    "        ex = i['train']['image']\n",
    "        \n",
    "        \n",
    "So, next(iter()) just gives you one i, but in case your data have number of images > number of batch size(8 in our case). the iteration will iterate until number of images will be finished  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:47:07.902819Z",
     "iopub.status.busy": "2023-02-17T08:47:07.901439Z",
     "iopub.status.idle": "2023-02-17T08:47:18.278254Z",
     "shell.execute_reply": "2023-02-17T08:47:18.277002Z",
     "shell.execute_reply.started": "2023-02-17T08:47:07.902774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:47:32.502105Z",
     "iopub.status.busy": "2023-02-17T08:47:32.501222Z",
     "iopub.status.idle": "2023-02-17T08:47:32.513117Z",
     "shell.execute_reply": "2023-02-17T08:47:32.511251Z",
     "shell.execute_reply.started": "2023-02-17T08:47:32.502063Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerModel, SegformerConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "from transformers import SegformerPreTrainedModel, SegformerForSemanticSegmentation\n",
    "\n",
    "from transformers import SegformerModel, SegformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:47:32.634454Z",
     "iopub.status.busy": "2023-02-17T08:47:32.634033Z",
     "iopub.status.idle": "2023-02-17T08:47:32.652185Z",
     "shell.execute_reply": "2023-02-17T08:47:32.650675Z",
     "shell.execute_reply.started": "2023-02-17T08:47:32.634420Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSegFormer2(SegformerPreTrainedModel):\n",
    "    def __init__(self, config, in_channel, n_classes=5):\n",
    "        super().__init__(config)\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b4-finetuned-ade-512-512\", ignore_mismatched_sizes=True)\n",
    "        self.logits_outputs = nn.Conv2d(in_channel, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "        self.distance_outputs = nn.Conv2d(in_channel, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        # forward to get raw logits\n",
    "        outputs = self.segformer(pixel_values) # what's the number of output channels?\n",
    "        logits_outputs = self.logits_outputs(outputs[0])\n",
    "        distancemap_outputs = self.distance_outputs(outputs[0])        \n",
    "\n",
    "        # next, do whatever you want with the logits to compute loss\n",
    "        # upsample logits here; the predicted distance map is also needed to unsampled, right?\n",
    "        upsampled_logits = nn.functional.interpolate(logits_outputs, size=pixel_values.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        upsampled_distancemaps = nn.functional.interpolate(distancemap_outputs , size=pixel_values.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        # calculate losses for logits and distance map respectively and sum the two losses\n",
    "        \n",
    "        return  upsampled_logits, upsampled_distancemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T08:48:18.714179Z",
     "iopub.status.busy": "2023-02-17T08:48:18.713789Z",
     "iopub.status.idle": "2023-02-17T08:48:25.628461Z",
     "shell.execute_reply": "2023-02-17T08:48:25.627435Z",
     "shell.execute_reply.started": "2023-02-17T08:48:18.714146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5632380d4ce347c48ecccf762ea83fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/6.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d7582ecebb468893e3804c0def0308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import SegformerModel, SegformerConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ex=torch.rand(8,3,224,224)\n",
    "\n",
    "configuration = SegformerConfig()\n",
    "model=CustomSegFormer2(configuration,in_channel=150)\n",
    "logits, _ = model(ex)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output note\n",
    "for the loss, put the logits and the GT directly, \n",
    "But before the argmax function for calculting IOU you have first to enter the logits into softmax function: \n",
    "ex -- > Argmax(Softmax(Logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now what is next: \n",
    "I gave you some hints, now you can start from here and open any kaggle competition to see how to run training pipline for segmentation, it is supposed also to know how to run training segmetnation pipline if you have a look on any kaggle the classification pipline. Just be comfort with dataloader variable I llustriate in the previous cells and actually they repressents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if you have any question send to me i will be able to reply from 6:00 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0987726327b6c9b2f5f936e5ed66944479e247a882213e2c65b0f41fe619a749"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
